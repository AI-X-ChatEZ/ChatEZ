{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Lq9QSG9nP8p1",
        "-ygBFNUDRM9K",
        "u75SJkB-RQrc"
      ],
      "authorship_tag": "ABX9TyNw/Sw86ysYaBLT5/Ra6OjK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-X-ChatEZ/ChatEZ/blob/dk/BM25_SBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-72svhYzGLaG",
        "outputId": "79f46477-dfe5-4120-d1b3-44e6b51795f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: python-mecab-ko in /usr/local/lib/python3.10/dist-packages (1.3.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (0.8.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.23.5)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: python-mecab-ko-dic in /usr/local/lib/python3.10/dist-packages (from python-mecab-ko) (2.1.1.post2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.34.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.27.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (17.0.1)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.14.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install rank_bm25 konlpy nltk python-mecab-ko openai sentence_transformers python-docx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrzUVSoBx7Y6",
        "outputId": "bc7b4efb-b311-4b56-c9cd-79f23d6374fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### max len test"
      ],
      "metadata": {
        "id": "Lq9QSG9nP8p1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'aaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa v aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa  '\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('jhgan/ko-sbert-multitask')\n",
        "print(len(tokenizer(text)['input_ids']))\n",
        "print(len(text))\n",
        "\n",
        "model.max_seq_length = 1\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 2\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 3\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 4\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 5\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 6\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 7\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 8\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 10\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 30\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 100\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 128\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 200\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "print('TEST')\n",
        "model.max_seq_length = 400\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 410\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 420\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 430\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "print('여긴가?')\n",
        "model.max_seq_length = 440\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 450\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 460\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 470\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 700\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 775\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 773\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 778\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "text = 'aa'\n",
        "\n",
        "model.max_seq_length = 1\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 2\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 3\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 4\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 10\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 30\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "text = 'a'\n",
        "\n",
        "model.max_seq_length = 1\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 2\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 3\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 4\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 10\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "model.max_seq_length = 30\n",
        "a = model.encode(text)\n",
        "print(a[0:4])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KSuGZtaG1x9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 고려할것\n",
        "- 쇼핑몰 챗봇의 경우 cs가 대부분이다. (교환/환불)\n",
        "- 이런 것들을 어떻게 처리 해야 할 것인강?"
      ],
      "metadata": {
        "id": "vIlVrl108wv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import openai\n",
        "import pandas as pd\n",
        "from mecab import MeCab\n",
        "from konlpy.tag import *\n",
        "from docx import Document\n",
        "from rank_bm25 import BM25Okapi\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "uudDUWo9v2Co"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "BkCgc9HNQbqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-zA-Zㄱ-ㅣ가-힣0-9:\\$€¥£.?!,\\n\\(\\) ]\", \" \", text)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "AxjJuy_v6d0Y"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 임베딩 모델"
      ],
      "metadata": {
        "id": "9h8LM92kQpqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
        "model.max_seq_length = 512"
      ],
      "metadata": {
        "id": "Zy3nQBQUv8A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 토크나이저 함수\n",
        "- 문제점 : 한국어 tokenizer를 쓰니 영어가 다 사라짐\n",
        "    - 한국어 tokenizer + 영어 tokenizer 합치자\n",
        "    - BERT tokenizer 쓰자"
      ],
      "metadata": {
        "id": "eFfFBBRtQnel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hannanum = Hannanum()\n",
        "# okt = Okt()\n",
        "# kkma = Kkma()\n",
        "# komoran = Komoran()\n",
        "mecab = MeCab()\n",
        "\n",
        "tokenizer = mecab # mecab\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "def mixed_tokenizer(text):\n",
        "    # 한글과 영어를 분리\n",
        "    korean_text = re.sub('[^가-힣\\s]', '', text)\n",
        "    english_text = re.sub('[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    korean_tokens = mecab.nouns(korean_text)\n",
        "    english_tokens = nltk.word_tokenize(english_text)\n",
        "    return korean_tokens + english_tokens\n",
        "\n",
        "# BERT Tokenizer\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"jhgan/ko-sroberta-multitask\") # bert tokenizer"
      ],
      "metadata": {
        "id": "mY0IQemcv7Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문장 길이로 문장 쪼개는 함수"
      ],
      "metadata": {
        "id": "HC9eYFtoQls0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# len 길이로 split\n",
        "def split_sentences(text):\n",
        "    if not text:  # 값 비어있는 경우\n",
        "        return []\n",
        "\n",
        "    sentences = text.split('\\n')\n",
        "    result = []\n",
        "    current_sentence = ''\n",
        "    for sentence in sentences:\n",
        "        if (len(sentence) > 300) and (current_sentence == ''):\n",
        "            result.append(sentence)\n",
        "            continue\n",
        "\n",
        "        if len(current_sentence) + len(sentence) <= 300:\n",
        "            current_sentence += ' ' + sentence\n",
        "        else:\n",
        "            result.append(current_sentence)\n",
        "            current_sentence = ' ' + sentence\n",
        "\n",
        "    # 마지막 문장 추가\n",
        "    if current_sentence:\n",
        "        result.append(current_sentence)\n",
        "    return result"
      ],
      "metadata": {
        "id": "Gz_ayAMmQSqs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token 수 기준으로 문장 쪼개는 함수"
      ],
      "metadata": {
        "id": "8zpNs1v9Qhc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# token 수로 split 하기\n",
        "def split_by_tokens(text, max_tokens=200):\n",
        "    if not text:  # 값 비어있는 경우\n",
        "        return []\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"jhgan/ko-sroberta-multitask\")\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    if len(tokens) <= max_tokens:\n",
        "        return [text]\n",
        "\n",
        "    sentences = text.split('\\n')\n",
        "    result = []\n",
        "    current_text = ''\n",
        "    current_tokens = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence_tokens = tokenizer.tokenize(sentence)\n",
        "\n",
        "        if len(current_tokens) + len(sentence_tokens) <= max_tokens:\n",
        "            current_text += ' ' + sentence # 마지막 단어와 다음 단어가 붙음 (구현정)\n",
        "            current_tokens.extend(sentence_tokens)\n",
        "        else:\n",
        "            if current_text.strip():\n",
        "                result.append(current_text)\n",
        "            current_text = ' ' + sentence\n",
        "            current_tokens = sentence_tokens\n",
        "\n",
        "    # 마지막 문장 추가\n",
        "    if current_text:\n",
        "        result.append(current_text)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "L5JTN19DQUKo"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 임베딩 함수"
      ],
      "metadata": {
        "id": "oCrBoqF3Qc-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embeddings(text):\n",
        "    text = model.encode(text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "xgoOxs1OQZQU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine 유사도 함수"
      ],
      "metadata": {
        "id": "CdMD4Nk5QeGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cossim(text):\n",
        "    cossim = util.cos_sim(query_embeding, text)\n",
        "    return cossim"
      ],
      "metadata": {
        "id": "Vxp-ww6rQW6Z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터"
      ],
      "metadata": {
        "id": "sFmj4QYgRETu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이콘 FAQ\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/하이미디/하이미디어 2차 프로젝트/데이콘 Q&A.xlsx\")\n",
        "df[\"data\"] = \"Question : \" + df[\"Question\"] + \" Answer : \" + df[\"Answer\"]\n",
        "\n",
        "# 아이폰 15 데이터\n",
        "# df = pd.read_excel(\"/content/drive/MyDrive/하이미디/하이미디어 2차 프로젝트/아이폰15.xlsx\")\n",
        "\n",
        "# 삼성카드 데이터\n",
        "# df = pd.read_excel(\"/content/drive/MyDrive/하이미디/하이미디어 2차 프로젝트/삼성카드 FAQ10 + 카드 신청.xlsx\")\n",
        "# df[\"data\"] = \"Question : \" + df[\"Question\"] + \" Answer : \" + df[\"Answer\"]\n",
        "\n",
        "# ChatEZ 데이터\n",
        "# doc = Document(\"/content/drive/MyDrive/하이미디/하이미디어 2차 프로젝트/ChatEZ.docx\")\n",
        "# # df = doc.Document('')\n",
        "# full_text = []\n",
        "# for para in doc.paragraphs:\n",
        "#     full_text.append(para.text)\n",
        "# text = '\\n'.join(full_text)\n",
        "# df = pd.DataFrame({'data': [text]})"
      ],
      "metadata": {
        "id": "-6heq7IuLltE"
      },
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전처리"
      ],
      "metadata": {
        "id": "_B7-wzQ7RF4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리\n",
        "df[\"data\"] = df[\"data\"].apply(preprocessing)"
      ],
      "metadata": {
        "id": "QdLSClLRjsSr"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 split\n",
        "- 문제점 : Question같이 문장 앞부분에 오는게 짤림"
      ],
      "metadata": {
        "id": "39HPmsV74h8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 길이 기준으로 split\n",
        "# df['data'] = df['data'].apply(split_sentences).explode().reset_index(drop=True)\n",
        "\n",
        "# 토큰수 기준으로 split\n",
        "df['data'] = df['data'].apply(split_by_tokens)\n",
        "\n",
        "df = df.explode('data').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "bSAfyXo44h_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 토큰화\n"
      ],
      "metadata": {
        "id": "IqogJ6Jp4mip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BM25 토큰화\n",
        "df[\"BM25_tokenized\"] = df[\"data\"].apply(mixed_tokenizer)\n",
        "\n",
        "# df[\"BM25_tokenized\"] = df[\"data\"].apply(tokenizer.tokenize) # bert tokenizer"
      ],
      "metadata": {
        "id": "GWjKrZsx4mnH"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 임베딩"
      ],
      "metadata": {
        "id": "N2oBKPCl4pUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SBERT 임베딩\n",
        "df[\"SBERT_Embedding\"] = df[\"data\"].apply(embeddings)"
      ],
      "metadata": {
        "id": "O4hYFuDH4pYe"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 확인"
      ],
      "metadata": {
        "id": "MNphvGJCF2x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "H7I3y2pCJSFo",
        "outputId": "f799db4f-a0f3-4a7c-8ec9-6f86e0220f5c"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 Question  \\\n",
              "0       Q. 데이콘에서 개최하는 대회는 어떤 종류와 특징이 있나요?   \n",
              "1       Q. 데이콘에서 개최하는 대회는 어떤 종류와 특징이 있나요?   \n",
              "2        Q. 대회에 참가할 때 데이콘 가입과 로그인은 필수인가요?   \n",
              "3                          Q. DACON 계정 삭제   \n",
              "4                          Q. DACON 계정 삭제   \n",
              "5                       Q. 계정을 변경할 수 있나요?   \n",
              "6     Q. 이미 인증된 핸드폰 번호라고 표시되는 경우 어떻게 하나요?   \n",
              "7                Q. 탈퇴 후 계정을 새로 만들 수 있나요?   \n",
              "8   Q. 데이콘에 가입한 소셜 계정을 삭제해서 로그인을 할 수 없어요.   \n",
              "9                   Q. 핸드폰에 인증 번호가 오지 않아요   \n",
              "10                     Q. 계정을 초기화할 수 있나요?   \n",
              "11       Q. 팀장 또는 팀원이 하루에 여러 번 제출이 가능한가요?   \n",
              "12                 Q. 단체에서 대회에 참가할 수 있나요?   \n",
              "13                        Q. 팀을 옮길 수 있나요?   \n",
              "14          Q. 어떤 행위가 부정 제출에 해당하는지 궁금합니다.   \n",
              "15          Q. 어떤 행위가 부정 제출에 해당하는지 궁금합니다.   \n",
              "16               Q. 지난 대회의 데이터는 받을 수 없나요?   \n",
              "\n",
              "                                               Answer  \\\n",
              "0   컴피티션 / 해커톤 : 대회는 크게 '컴피티션'과 '해커톤'으로 구분이 됩니다. '...   \n",
              "1   컴피티션 / 해커톤 : 대회는 크게 '컴피티션'과 '해커톤'으로 구분이 됩니다. '...   \n",
              "2   대회에 참가하기 위해서는 데이콘 회원 가입 후 로그인이 필요합니다.\\n\\n로그인 후...   \n",
              "3   탈퇴 신청 전 아래 사항을 반드시 확인해 주세요.\\n\\n회원 탈퇴 시 30일간 재가...   \n",
              "4   탈퇴 신청 전 아래 사항을 반드시 확인해 주세요.\\n\\n회원 탈퇴 시 30일간 재가...   \n",
              "5   데이콘은 대회 공정성을 위해 1인 1계정을 원칙으로 하고 있습니다.\\n\\n핸드폰 본...   \n",
              "6   이미 인증된 번호라고 표시되는 것은 다른 계정으로 가입된 이력이 존재한다는 의미입니...   \n",
              "7   탈퇴 후, 30일 이후에 새로운 계정을 만들 수 있습니다.\\n\\n(단, 탈퇴 시 기...   \n",
              "8   데이콘에 가입하셨던 소셜 계정(페이스북,구글 등)을 삭제하셨을 경우, 본인 확인 후...   \n",
              "9   해외 발신 문자 거부나 스팸 차단 등의 서비스를 이용하고 계실 경우, 인증 번호를 ...   \n",
              "10  데이콘은 계정 초기화 서비스를 지원하고 있지 않습니다.\\n\\n초기화를 원하시면 회원...   \n",
              "11  제출은 팀장 및 팀원 모두 가능합니다.\\n\\n\\n\\n단, 하루 최대 제출 횟수에 제...   \n",
              "12  학교, 기업, 교육 업체 등에서 다수 팀으로 대회에 참가하는 경우 아래 주의사항이 ...   \n",
              "13  팀을 옮기는 것은 기존 팀의 아이디어가 다른 팀에 공유되는 것으로 판단되기 때문에,...   \n",
              "14  각 대회별로 정해져 있는 최대 제출 횟수를 직접적, 간접적으로 넘기는 행위\\n\\n\\...   \n",
              "15  각 대회별로 정해져 있는 최대 제출 횟수를 직접적, 간접적으로 넘기는 행위\\n\\n\\...   \n",
              "16  상업적 사용 외 개인 연구, 스터디 목적으로는 다운로드가 가능합니다.\\n\\n단, 사...   \n",
              "\n",
              "                                                 data  \\\n",
              "0    Question : Q. 데이콘에서 개최하는 대회는 어떤 종류와 특징이 있나요? ...   \n",
              "1    구인구직 대회 : 스폰서 기업의 요구사항에 맞게 빅데이터 대회를 주최하고 데이터 ...   \n",
              "2   Question : Q. 대회에 참가할 때 데이콘 가입과 로그인은 필수인가요? An...   \n",
              "3    Question : Q. DACON 계정 삭제 Answer : 탈퇴 신청 전 아래...   \n",
              "4    회원님의 프로필 정보(대회 참여 이력, 제출 정보 등) 이력은 모두 삭제되며, 삭...   \n",
              "5   Question : Q. 계정을 변경할 수 있나요? Answer : 데이콘은 대회 ...   \n",
              "6   Question : Q. 이미 인증된 핸드폰 번호라고 표시되는 경우 어떻게 하나요?...   \n",
              "7   Question : Q. 탈퇴 후 계정을 새로 만들 수 있나요? Answer : 탈...   \n",
              "8   Question : Q. 데이콘에 가입한 소셜 계정을 삭제해서 로그인을 할 수 없어...   \n",
              "9   Question : Q. 핸드폰에 인증 번호가 오지 않아요 Answer : 해외 발...   \n",
              "10  Question : Q. 계정을 초기화할 수 있나요? Answer : 데이콘은 계정...   \n",
              "11  Question : Q. 팀장 또는 팀원이 하루에 여러 번 제출이 가능한가요? An...   \n",
              "12  Question : Q. 단체에서 대회에 참가할 수 있나요? Answer : 학교,...   \n",
              "13  Question : Q. 팀을 옮길 수 있나요? Answer : 팀을 옮기는 것은 ...   \n",
              "14   Question : Q. 어떤 행위가 부정 제출에 해당하는지 궁금합니다. Answ...   \n",
              "15   부정 제출이 발견될 시 통보 없이 해당 대회의 리더보드에서 기록 삭제, 수상 자격...   \n",
              "16  Question : Q. 지난 대회의 데이터는 받을 수 없나요? Answer : 상...   \n",
              "\n",
              "                                       BM25_tokenized  \\\n",
              "0   [이콘, 개최, 대회, 종류, 특징, 컴, 피티, 션, 해커, 톤, 대회, 컴, 피...   \n",
              "1   [구인, 구직, 대회, 스폰서, 기업, 요구사항, 빅, 데이터, 대회, 주최, 데이...   \n",
              "2   [대회, 참가, 때, 데이, 콘, 가입, 로그인, 필수, 대회, 참가, 데이, 콘,...   \n",
              "3   [계정, 삭제, 탈퇴, 신청, 전, 아래, 사항, 확인, 회원, 탈퇴, 시, 일간,...   \n",
              "4   [회원, 프로필, 정보, 대회, 참여, 이력, 제출, 정보, 등, 이력, 삭제, 삭...   \n",
              "5   [계정, 변경, 수, 데이, 콘, 대회, 공정, 인, 계정, 원칙, 핸드폰, 본인,...   \n",
              "6   [인증, 핸드폰, 번호, 표시, 경우, 인증, 번호, 표시, 것, 계정, 가입, 이...   \n",
              "7   [탈퇴, 후, 계정, 수, 탈퇴, 후, 일, 이후, 계정, 수, 탈퇴, 시, 기존,...   \n",
              "8   [데이, 콘, 가입, 소셜, 계정, 삭제, 로그인, 수, 이콘, 가입, 소셜, 계정...   \n",
              "9   [핸드폰, 인증, 번호, 해외, 발신, 문자, 거부, 스팸, 차단, 등, 서비스, ...   \n",
              "10  [계정, 초기, 수, 데이, 콘, 계정, 초기, 서비스, 지원, 초기, 회원, 탈퇴...   \n",
              "11  [팀장, 팀원, 하루, 번, 제출, 가능, 가요, 제출, 팀장, 팀원, 가능, 하루...   \n",
              "12  [단체, 대회, 참가, 수, 학교, 기업, 교육, 업체, 등, 다수, 팀, 대회, ...   \n",
              "13  [팀, 수, 팀, 것, 기존, 팀, 아이디어, 팀, 공유, 것, 판단, 때문, 팀,...   \n",
              "14  [행위, 부정, 제출, 해당, 대회, 최대, 제출, 횟수, 직접, 간접, 행위, 사...   \n",
              "15  [부정, 제출, 발견, 시, 통보, 해당, 대회, 리더, 보드, 기록, 삭제, 수상...   \n",
              "16  [대회, 데이터, 수, 상업, 사용, 외, 개인, 연구, 스터디, 목적, 다운로드,...   \n",
              "\n",
              "                                      SBERT_Embedding  \n",
              "0   [-0.72251135, -0.37383828, 0.409599, 1.058895,...  \n",
              "1   [-0.77829826, 0.6646773, 0.13040513, 1.5459656...  \n",
              "2   [-0.93674755, -0.16263703, -0.32769668, 0.5756...  \n",
              "3   [-0.36891186, 0.5700454, -0.11711333, 0.112015...  \n",
              "4   [-0.8872062, 0.6604706, 0.31621787, 0.92908365...  \n",
              "5   [-0.112184025, -0.6984228, -0.29453668, 0.5242...  \n",
              "6   [-0.25213778, 0.09400679, -0.11131315, 0.75443...  \n",
              "7   [-0.55083686, 0.65238965, -0.043946125, -0.098...  \n",
              "8   [-0.36638564, 0.2617641, -0.13122173, 0.645521...  \n",
              "9   [0.1283261, -0.016809026, -0.45954582, 0.93933...  \n",
              "10  [-0.52826536, -0.327313, -0.39517468, 0.464904...  \n",
              "11  [-0.054204516, 0.28226316, -0.64848316, -0.128...  \n",
              "12  [-0.25888544, 0.2733273, -0.35624376, 0.080024...  \n",
              "13  [-0.21623512, -0.041603353, -0.031729303, 0.44...  \n",
              "14  [0.035071064, -0.3851516, -0.13209307, 0.47637...  \n",
              "15  [-0.19889373, 0.25900912, 0.53242534, 0.813568...  \n",
              "16  [-0.38604686, -0.11203227, 0.14602968, 0.44781...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab1cb8ba-b69a-4c7a-8006-4ac896c278ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>data</th>\n",
              "      <th>BM25_tokenized</th>\n",
              "      <th>SBERT_Embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q. 데이콘에서 개최하는 대회는 어떤 종류와 특징이 있나요?</td>\n",
              "      <td>컴피티션 / 해커톤 : 대회는 크게 '컴피티션'과 '해커톤'으로 구분이 됩니다. '...</td>\n",
              "      <td>Question : Q. 데이콘에서 개최하는 대회는 어떤 종류와 특징이 있나요? ...</td>\n",
              "      <td>[이콘, 개최, 대회, 종류, 특징, 컴, 피티, 션, 해커, 톤, 대회, 컴, 피...</td>\n",
              "      <td>[-0.72251135, -0.37383828, 0.409599, 1.058895,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q. 데이콘에서 개최하는 대회는 어떤 종류와 특징이 있나요?</td>\n",
              "      <td>컴피티션 / 해커톤 : 대회는 크게 '컴피티션'과 '해커톤'으로 구분이 됩니다. '...</td>\n",
              "      <td>구인구직 대회 : 스폰서 기업의 요구사항에 맞게 빅데이터 대회를 주최하고 데이터 ...</td>\n",
              "      <td>[구인, 구직, 대회, 스폰서, 기업, 요구사항, 빅, 데이터, 대회, 주최, 데이...</td>\n",
              "      <td>[-0.77829826, 0.6646773, 0.13040513, 1.5459656...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q. 대회에 참가할 때 데이콘 가입과 로그인은 필수인가요?</td>\n",
              "      <td>대회에 참가하기 위해서는 데이콘 회원 가입 후 로그인이 필요합니다.\\n\\n로그인 후...</td>\n",
              "      <td>Question : Q. 대회에 참가할 때 데이콘 가입과 로그인은 필수인가요? An...</td>\n",
              "      <td>[대회, 참가, 때, 데이, 콘, 가입, 로그인, 필수, 대회, 참가, 데이, 콘,...</td>\n",
              "      <td>[-0.93674755, -0.16263703, -0.32769668, 0.5756...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q. DACON 계정 삭제</td>\n",
              "      <td>탈퇴 신청 전 아래 사항을 반드시 확인해 주세요.\\n\\n회원 탈퇴 시 30일간 재가...</td>\n",
              "      <td>Question : Q. DACON 계정 삭제 Answer : 탈퇴 신청 전 아래...</td>\n",
              "      <td>[계정, 삭제, 탈퇴, 신청, 전, 아래, 사항, 확인, 회원, 탈퇴, 시, 일간,...</td>\n",
              "      <td>[-0.36891186, 0.5700454, -0.11711333, 0.112015...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q. DACON 계정 삭제</td>\n",
              "      <td>탈퇴 신청 전 아래 사항을 반드시 확인해 주세요.\\n\\n회원 탈퇴 시 30일간 재가...</td>\n",
              "      <td>회원님의 프로필 정보(대회 참여 이력, 제출 정보 등) 이력은 모두 삭제되며, 삭...</td>\n",
              "      <td>[회원, 프로필, 정보, 대회, 참여, 이력, 제출, 정보, 등, 이력, 삭제, 삭...</td>\n",
              "      <td>[-0.8872062, 0.6604706, 0.31621787, 0.92908365...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Q. 계정을 변경할 수 있나요?</td>\n",
              "      <td>데이콘은 대회 공정성을 위해 1인 1계정을 원칙으로 하고 있습니다.\\n\\n핸드폰 본...</td>\n",
              "      <td>Question : Q. 계정을 변경할 수 있나요? Answer : 데이콘은 대회 ...</td>\n",
              "      <td>[계정, 변경, 수, 데이, 콘, 대회, 공정, 인, 계정, 원칙, 핸드폰, 본인,...</td>\n",
              "      <td>[-0.112184025, -0.6984228, -0.29453668, 0.5242...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Q. 이미 인증된 핸드폰 번호라고 표시되는 경우 어떻게 하나요?</td>\n",
              "      <td>이미 인증된 번호라고 표시되는 것은 다른 계정으로 가입된 이력이 존재한다는 의미입니...</td>\n",
              "      <td>Question : Q. 이미 인증된 핸드폰 번호라고 표시되는 경우 어떻게 하나요?...</td>\n",
              "      <td>[인증, 핸드폰, 번호, 표시, 경우, 인증, 번호, 표시, 것, 계정, 가입, 이...</td>\n",
              "      <td>[-0.25213778, 0.09400679, -0.11131315, 0.75443...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Q. 탈퇴 후 계정을 새로 만들 수 있나요?</td>\n",
              "      <td>탈퇴 후, 30일 이후에 새로운 계정을 만들 수 있습니다.\\n\\n(단, 탈퇴 시 기...</td>\n",
              "      <td>Question : Q. 탈퇴 후 계정을 새로 만들 수 있나요? Answer : 탈...</td>\n",
              "      <td>[탈퇴, 후, 계정, 수, 탈퇴, 후, 일, 이후, 계정, 수, 탈퇴, 시, 기존,...</td>\n",
              "      <td>[-0.55083686, 0.65238965, -0.043946125, -0.098...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Q. 데이콘에 가입한 소셜 계정을 삭제해서 로그인을 할 수 없어요.</td>\n",
              "      <td>데이콘에 가입하셨던 소셜 계정(페이스북,구글 등)을 삭제하셨을 경우, 본인 확인 후...</td>\n",
              "      <td>Question : Q. 데이콘에 가입한 소셜 계정을 삭제해서 로그인을 할 수 없어...</td>\n",
              "      <td>[데이, 콘, 가입, 소셜, 계정, 삭제, 로그인, 수, 이콘, 가입, 소셜, 계정...</td>\n",
              "      <td>[-0.36638564, 0.2617641, -0.13122173, 0.645521...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Q. 핸드폰에 인증 번호가 오지 않아요</td>\n",
              "      <td>해외 발신 문자 거부나 스팸 차단 등의 서비스를 이용하고 계실 경우, 인증 번호를 ...</td>\n",
              "      <td>Question : Q. 핸드폰에 인증 번호가 오지 않아요 Answer : 해외 발...</td>\n",
              "      <td>[핸드폰, 인증, 번호, 해외, 발신, 문자, 거부, 스팸, 차단, 등, 서비스, ...</td>\n",
              "      <td>[0.1283261, -0.016809026, -0.45954582, 0.93933...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Q. 계정을 초기화할 수 있나요?</td>\n",
              "      <td>데이콘은 계정 초기화 서비스를 지원하고 있지 않습니다.\\n\\n초기화를 원하시면 회원...</td>\n",
              "      <td>Question : Q. 계정을 초기화할 수 있나요? Answer : 데이콘은 계정...</td>\n",
              "      <td>[계정, 초기, 수, 데이, 콘, 계정, 초기, 서비스, 지원, 초기, 회원, 탈퇴...</td>\n",
              "      <td>[-0.52826536, -0.327313, -0.39517468, 0.464904...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Q. 팀장 또는 팀원이 하루에 여러 번 제출이 가능한가요?</td>\n",
              "      <td>제출은 팀장 및 팀원 모두 가능합니다.\\n\\n\\n\\n단, 하루 최대 제출 횟수에 제...</td>\n",
              "      <td>Question : Q. 팀장 또는 팀원이 하루에 여러 번 제출이 가능한가요? An...</td>\n",
              "      <td>[팀장, 팀원, 하루, 번, 제출, 가능, 가요, 제출, 팀장, 팀원, 가능, 하루...</td>\n",
              "      <td>[-0.054204516, 0.28226316, -0.64848316, -0.128...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Q. 단체에서 대회에 참가할 수 있나요?</td>\n",
              "      <td>학교, 기업, 교육 업체 등에서 다수 팀으로 대회에 참가하는 경우 아래 주의사항이 ...</td>\n",
              "      <td>Question : Q. 단체에서 대회에 참가할 수 있나요? Answer : 학교,...</td>\n",
              "      <td>[단체, 대회, 참가, 수, 학교, 기업, 교육, 업체, 등, 다수, 팀, 대회, ...</td>\n",
              "      <td>[-0.25888544, 0.2733273, -0.35624376, 0.080024...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Q. 팀을 옮길 수 있나요?</td>\n",
              "      <td>팀을 옮기는 것은 기존 팀의 아이디어가 다른 팀에 공유되는 것으로 판단되기 때문에,...</td>\n",
              "      <td>Question : Q. 팀을 옮길 수 있나요? Answer : 팀을 옮기는 것은 ...</td>\n",
              "      <td>[팀, 수, 팀, 것, 기존, 팀, 아이디어, 팀, 공유, 것, 판단, 때문, 팀,...</td>\n",
              "      <td>[-0.21623512, -0.041603353, -0.031729303, 0.44...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Q. 어떤 행위가 부정 제출에 해당하는지 궁금합니다.</td>\n",
              "      <td>각 대회별로 정해져 있는 최대 제출 횟수를 직접적, 간접적으로 넘기는 행위\\n\\n\\...</td>\n",
              "      <td>Question : Q. 어떤 행위가 부정 제출에 해당하는지 궁금합니다. Answ...</td>\n",
              "      <td>[행위, 부정, 제출, 해당, 대회, 최대, 제출, 횟수, 직접, 간접, 행위, 사...</td>\n",
              "      <td>[0.035071064, -0.3851516, -0.13209307, 0.47637...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Q. 어떤 행위가 부정 제출에 해당하는지 궁금합니다.</td>\n",
              "      <td>각 대회별로 정해져 있는 최대 제출 횟수를 직접적, 간접적으로 넘기는 행위\\n\\n\\...</td>\n",
              "      <td>부정 제출이 발견될 시 통보 없이 해당 대회의 리더보드에서 기록 삭제, 수상 자격...</td>\n",
              "      <td>[부정, 제출, 발견, 시, 통보, 해당, 대회, 리더, 보드, 기록, 삭제, 수상...</td>\n",
              "      <td>[-0.19889373, 0.25900912, 0.53242534, 0.813568...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Q. 지난 대회의 데이터는 받을 수 없나요?</td>\n",
              "      <td>상업적 사용 외 개인 연구, 스터디 목적으로는 다운로드가 가능합니다.\\n\\n단, 사...</td>\n",
              "      <td>Question : Q. 지난 대회의 데이터는 받을 수 없나요? Answer : 상...</td>\n",
              "      <td>[대회, 데이터, 수, 상업, 사용, 외, 개인, 연구, 스터디, 목적, 다운로드,...</td>\n",
              "      <td>[-0.38604686, -0.11203227, 0.14602968, 0.44781...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab1cb8ba-b69a-4c7a-8006-4ac896c278ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab1cb8ba-b69a-4c7a-8006-4ac896c278ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab1cb8ba-b69a-4c7a-8006-4ac896c278ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-77219ad6-bdca-4be8-b058-c3f68df2a90c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-77219ad6-bdca-4be8-b058-c3f68df2a90c')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-77219ad6-bdca-4be8-b058-c3f68df2a90c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BM25 단독"
      ],
      "metadata": {
        "id": "-ygBFNUDRM9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BM25\n",
        "preconv=[]\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "while True:\n",
        "\n",
        "    # 사용자 Query 입력\n",
        "    query = input(\"사용자 질문 입력 : \")\n",
        "    print()\n",
        "\n",
        "    # BM25\n",
        "    query_token = tokenizer.nouns(query)\n",
        "\n",
        "    ####????#####\n",
        "    # 왜 data 를 넣어주지? tokenized 된게 아니고?? tokenized된거를 넣어주면 selected에 토큰이 들어가서 gpt한테 제대로 주는게 안된다\n",
        "    # BM25_selected_docs = bm25.get_top_n(query_token, df[\"data\"], n=5)\n",
        "\n",
        "    bm25 = BM25Okapi(df[\"BM25_tokenized\"])\n",
        "    df['BM25_score'] = pd.DataFrame(bm25.get_scores(query_token))\n",
        "    df = df.sort_values(by=[\"BM25_score\"], ascending=False)\n",
        "    BM25_selected_docs = list(df.iloc[:5][\"data\"])\n",
        "    print(BM25_selected_docs)\n",
        "    selected_doc = \" \".join(BM25_selected_docs)\n",
        "\n",
        "    # BM25 답변\n",
        "    print('챗봇 답변(BM25)')\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            preconvs = ' '.join(preconv)\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Assistant is a chatbot.\"},\n",
        "                    {\"role\": \"user\", \"content\": '''If there is a previous conversation, create an answer by referring to the contents..\n",
        "                                                   previous conversation :''' + preconvs},\n",
        "                    {\"role\": \"user\", \"content\": ''' Create answers to user questions using related documents.\n",
        "                                                    If the related document is not relevant to your question, explain it based on your knowledge..\n",
        "                                                    make sure your answer is less than 600 tokens.'''\n",
        "                                                 + \"Related documents are as follows. [\" + selected_doc + ']. '\n",
        "                                                 + 'User questions are as follows. [' + query +']'\n",
        "                                                 + 'Create a response to deliver to customers. Answer in Korean.' }\n",
        "                ],\n",
        "                temperature=0,\n",
        "                max_tokens=600,\n",
        "                top_p=0.9,\n",
        "                frequency_penalty=0,\n",
        "                presence_penalty=0,\n",
        "            )\n",
        "\n",
        "            print(\"챗봇 답변 : \" + response[\"choices\"][0][\"message\"][\"content\"])\n",
        "            preconv.append('query:' + query + 'response:' + response[\"choices\"][0][\"message\"][\"content\"])\n",
        "\n",
        "            print()\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred: {e}\")\n",
        "            if len(preconv) > 0:\n",
        "                preconv.pop(0)\n",
        "            else:\n",
        "                BM25_selected_docs.pop()\n",
        "                continue\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bHOzAv8sRO4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SBERT 단독"
      ],
      "metadata": {
        "id": "u75SJkB-RQrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SBERT\n",
        "preconv=[]\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "while True:\n",
        "\n",
        "    # 사용자 Query 입력\n",
        "    query = input(\"사용자 질문 입력 : \")\n",
        "    print()\n",
        "\n",
        "    query_embeding = model.encode(query)\n",
        "    df[\"cossim\"] = df[\"SBERT_Embedding\"].apply(cossim)\n",
        "    df = df.sort_values(by=[\"cossim\"], ascending=False)\n",
        "    SBERT_selected_docs = list(df.iloc[:5][\"data\"])\n",
        "    print(SBERT_selected_docs)\n",
        "    selected_doc = \" \".join(SBERT_selected_docs)\n",
        "\n",
        "    # SBERT 답변\n",
        "    print('챗봇 답변(SBERT)')\n",
        "    while True:\n",
        "        try:\n",
        "            preconvs = ' '.join(preconv)\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Assistant is a chatbot.\"},\n",
        "                    {\"role\": \"user\", \"content\": '''If there is a previous conversation, create an answer by referring to the contents..\n",
        "                                                    previous conversation :''' + preconvs},\n",
        "                    {\"role\": \"user\", \"content\": ''' Create answers to user questions using related documents.\n",
        "                                                    If the related document is not relevant to your question, explain it based on your knowledge..\n",
        "                                                    make sure your answer is less than 600 tokens.'''\n",
        "                                                    + \"Related documents are as follows. [\" + selected_doc + ']. '\n",
        "                                                    + 'User questions are as follows. [' + query +']'\n",
        "                                                    + 'Create a response to deliver to customers. Answer in Korean.' }\n",
        "                ],\n",
        "                temperature=0,\n",
        "                max_tokens=600,\n",
        "                top_p=0.9,\n",
        "                frequency_penalty=0,\n",
        "                presence_penalty=0,\n",
        "            )\n",
        "            print(\"챗봇 답변 : \" + response[\"choices\"][0][\"message\"][\"content\"])\n",
        "            preconv.append('query:' + query + 'response:' + response[\"choices\"][0][\"message\"][\"content\"])\n",
        "\n",
        "            print()\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred: {e}\")\n",
        "            if len(preconv) > 0:\n",
        "                preconv.pop(0)\n",
        "            else:\n",
        "                SBERT_selected_docs.pop()\n",
        "                continue\n"
      ],
      "metadata": {
        "id": "6_qXKiAOfXf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BM25 + SBERT"
      ],
      "metadata": {
        "id": "u39kG_mNRUhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BM25 + SBERT\n",
        "openai.api_key = \"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\"\n",
        "scaler = MinMaxScaler()\n",
        "preconvs=[]\n",
        "while True:\n",
        "\n",
        "    # 사용자 Query 입력\n",
        "    query = input(\"사용자 질문 입력 : \")\n",
        "    print()\n",
        "    query = preprocessing(query)\n",
        "\n",
        "    # BM25\n",
        "    bm25 = BM25Okapi(df[\"BM25_tokenized\"])\n",
        "    # query_token = tokenizer.nouns(query) # mecab\n",
        "    query_token = mixed_tokenizer(query) # bert tokenizer\n",
        "    df['BM25_score'] = list(bm25.get_scores(query_token))\n",
        "    # 이거 처음에 df['BM25_score'] = pd.DataFrame(bm25.get_scores(query_token)) 했다가 인덱스 문제 발견함\n",
        "    df['BM25_score'] = scaler.fit_transform(df[['BM25_score']])\n",
        "\n",
        "    query_embeding = model.encode(query)\n",
        "    df[\"cossim\"] = df[\"SBERT_Embedding\"].apply(cossim)\n",
        "    df['cossim_score'] = scaler.fit_transform(df[['cossim']])\n",
        "\n",
        "    df['Hybrid_score'] = df['BM25_score'] *0.7 + df['cossim_score'] *0.3\n",
        "    df = df.sort_values(by=[\"Hybrid_score\"], ascending=False)\n",
        "    selected_docs = list(df.iloc[:5][\"data\"])\n",
        "\n",
        "\n",
        "    # print(selected_docs)\n",
        "\n",
        "    print('챗봇 답변(Hybrid)')\n",
        "    while True:\n",
        "        try:\n",
        "            preconv = ' '.join(preconvs)\n",
        "            selected_doc = \" \".join(selected_docs)\n",
        "\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Assistant is a chatbot.\"},\n",
        "                    {\"role\": \"user\", \"content\": '''If there is a previous conversation, create an answer by referring to the contents..\n",
        "                                                   previous conversation :''' + preconv},\n",
        "                    {\"role\": \"user\", \"content\": ''' Create answers to user questions using related documents.\n",
        "                                                    If the related document is not relevant to your question, explain it based on your knowledge.\n",
        "                                                    your answer is less than 300 tokens.'''\n",
        "                                                 + \"Related documents are as follows. [\" + selected_doc + ']. '\n",
        "                                                 + 'User questions are as follows. [' + query +']'\n",
        "                                                 + 'Create a response to deliver to customers. Answer in Korean.' }\n",
        "                # messages=[\n",
        "                #     {\"role\": \"system\", \"content\": \"assistant는 챗봇이다.\"},\n",
        "                #     {\"role\": \"user\", \"content\": '''previous conversation이 있다면 내용을 참고하여 답변을 만들 것.\n",
        "                #                                    previous conversation :''' + preconvs},\n",
        "                #     {\"role\": \"user\", \"content\": ''' 관련 문서를 활용하여 사용자 질문에 대한 답변을 만들어 줄 것.\n",
        "                #                                     관련 문서에 질문과 관련성이 없으면 너가 가진 지식으로 설명할 것.\n",
        "                #                                     답변은 600 token 이하로 만들어 줄 것.'''\n",
        "                #                                  + \"관련 문서는 아래와 같음. [\" + selected_doc + ']. '\n",
        "                #                                  + '사용자의 질문은 아래와 같음. [' + query +']'\n",
        "                #                                  + '고객에게 전달할 답변을 생성하는 것임.' }\n",
        "                ],\n",
        "                temperature=0,\n",
        "                max_tokens=400,\n",
        "                top_p=1,\n",
        "                frequency_penalty=0,\n",
        "                presence_penalty=0,\n",
        "            )\n",
        "\n",
        "            print(\"챗봇 답변 : \" + response[\"choices\"][0][\"message\"][\"content\"])\n",
        "            preconvs.append('query:' + query + 'response:' + response[\"choices\"][0][\"message\"][\"content\"])\n",
        "\n",
        "            print()\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred: {e}\")\n",
        "            if len(preconv) > 0:\n",
        "                preconvs.pop(0)\n",
        "            else:\n",
        "                selected_docs.pop()\n",
        "                if not selected_docs:\n",
        "                    print('질문이 너무 길엉')\n",
        "                    break\n",
        "                continue"
      ],
      "metadata": {
        "id": "yP5XOels_iSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-5Axn8achQhT"
      },
      "execution_count": 238,
      "outputs": []
    }
  ]
}